name: Sync Product Social Links
on:
  schedule:
    - cron: '0 * * * *' # Every hour
  workflow_dispatch: # Manual trigger

permissions:
  contents: write # Allows the bot to write to the 's' folder

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0 # Get full history for merging

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install Requests
        run: pip install requests

      - name: Generate Redirect Files
        run: |
          import csv
          import requests
          import os
          import re
          import urllib.parse

          SHEET_URL = "https://docs.google.com/spreadsheets/d/1-s7frQnY1Muh4XOizcz2V3KnkkHV8owNWYzyDrYFSic/gviz/tq?tqx=out:csv"
          BASE_URL = "https://animalhealth.pk"
          
          def get_clean_slug(name):
              if not name: return ""
              # STRICT SYNC WITH WEBSITE JS
              name = name.lower().replace('&', 'and')
              name = re.sub(r'\s+', '-', name)
              name = re.sub(r'[^a-z0-9-]', '', name)
              return name

          response = requests.get(SHEET_URL)
          decoded_content = response.content.decode('utf-8')
          cr = csv.reader(decoded_content.splitlines(), delimiter=',')
          rows = list(cr)

          # Ensure 's' is a directory
          if os.path.exists('s') and not os.path.isdir('s'):
              os.remove('s')
          if not os.path.exists('s'):
              os.makedirs('s')

          # Generate files
          for row in rows[1:]:
              if len(row) < 2 or not row[1].strip(): continue
              name = row[1].strip()
              desc = row[2].strip() if len(row) > 2 else ""
              img = row[3].strip() if len(row) > 3 and len(row[3]) > 5 else "https://tahirqadri88.github.io/khybertraders/images/website%20banner.jpg"
              slug = get_clean_slug(name)
              target = f"{BASE_URL}/?item={urllib.parse.quote(name)}"
              
              file_content = f"""<!DOCTYPE html><html><head><meta charset="UTF-8">
              <title>{name} | AnimalHealth.pk</title>
              <meta property="og:title" content="{name}">
              <meta property="og:description" content="{desc[:150]}">
              <meta property="og:image" content="{img}">
              <meta property="og:url" content="{target}">
              <meta property="og:type" content="website">
              <meta http-equiv="refresh" content="0;url={target}" />
              </head><body><script>window.location.href="{target}";</script></body></html>"""
              
              with open(f"s/{slug}.html", "w", encoding="utf-8") as f:
                  f.write(file_content)
          
      - name: Commit and Push Changes
        run: |
          git config --global user.name "Product-Bot"
          git config --global user.email "bot@animalhealth.pk"
          git add s/
          if git diff --staged --quiet; then
            echo "No changes found."
          else
            git commit -m "Auto-sync products: $(date)"
            git pull --rebase origin main
            git push origin main
          fi

